{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1f7912",
   "metadata": {},
   "source": [
    "# Import Some libraries to use it in our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "622a8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import hashlib\n",
    "import cv2 #module from the OpenCV (Open Source Computer Vision) library, . It provides functions for reading, writing, and manipulating images .  cv2 module is used to read the image files from the dataset directory, resize them to a fixed size, convert them to RGB color space, and normalize their pixel values to range [0, 1].\n",
    "import numpy as np\n",
    "from skimage import io, exposure\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67196c9a",
   "metadata": {},
   "source": [
    "# Read data device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5fa740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 2\n"
     ]
    }
   ],
   "source": [
    "categories = os.listdir(r\"F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\")\n",
    "num_categories = len(categories)\n",
    "print(\"Number of categories:\", num_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f994da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category to label mapping: {'no': 0, 'yes': 1}\n"
     ]
    }
   ],
   "source": [
    "category_to_label = {}\n",
    "for i, category in enumerate(categories):\n",
    "    category_to_label[category] = i\n",
    "print(\"Category to label mapping:\", category_to_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0c90c",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14f672",
   "metadata": {},
   "source": [
    "## Remove corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215fa006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove corrupt images\n",
    "def remove_corrupt_images(directory):\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            with Image.open(filepath) as img:\n",
    "                img.verify()\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            # Delete the corrupt image file\n",
    "            os.remove(filepath)\n",
    "            print(\"Removed corrupt image:\", filepath)\n",
    "\n",
    "remove_corrupt_images(r'F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\\yes')\n",
    "\n",
    "remove_corrupt_images(r'F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\\no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d9553",
   "metadata": {},
   "source": [
    "## Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c2efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    "# Define a function to resize images in a directory\n",
    "def resize_images(directory):\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        # Check if the file is an image\n",
    "        if filepath.endswith(\".jpg\") or filepath.endswith(\".png\") or filepath.endswith(\".jpeg\"):\n",
    "            \n",
    "            with Image.open(filepath) as img:\n",
    "                # Resize the image to the target size\n",
    "                resized_img = img.resize(target_size)\n",
    "                \n",
    "                # Convert RGBA to RGB if the image has an alpha channel\n",
    "                if resized_img.mode == 'RGBA':\n",
    "                    resized_img = resized_img.convert('RGB')\n",
    "                \n",
    "        \n",
    "                resized_img.save(filepath)\n",
    "\n",
    "\n",
    "\n",
    "resize_images(r'F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\\yes')\n",
    "\n",
    "resize_images(r'F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\\no')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eed661",
   "metadata": {},
   "source": [
    "## Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6837eb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to normalize images in a directory\n",
    "def normalize_images(directory):\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "    \n",
    "        if filepath.endswith(\".jpg\") or filepath.endswith(\".png\"):\n",
    "            \n",
    "            img = io.imread(filepath)\n",
    "            \n",
    "            normalized_img = exposure.rescale_intensity(img, in_range='image', out_range=(0,1)) \n",
    "            \n",
    "            io.imsave(filepath, normalized_img)\n",
    "\n",
    "normalize_images(r'F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\\yes')\n",
    "\n",
    "normalize_images(r'F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\\no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1e6ac",
   "metadata": {},
   "source": [
    "# Data Agumation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fde763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=45,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   validation_split = 0.3)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c1cce",
   "metadata": {},
   "source": [
    "# Split our data to training and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac94b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 177 images belonging to 2 classes.\n",
      "Found 75 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(r\"F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\",\n",
    "                                                 target_size=target_size,\n",
    "                                                batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                subset='training')\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory(r\"F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\",\n",
    "                                                  target_size=target_size,\n",
    "                                                 batch_size=32,\n",
    "                                      class_mode='categorical',\n",
    "                                               shuffle = False,\n",
    "                                           subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205ec90",
   "metadata": {},
   "source": [
    "# ANN ALGORITHM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9723ecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed Bayomey\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed Bayomey\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.4889 - loss: 1.0771 - val_accuracy: 0.6133 - val_loss: 3.3956\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.6694 - loss: 0.7478 - val_accuracy: 0.6267 - val_loss: 2.6960\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6817 - loss: 0.6014 - val_accuracy: 0.6533 - val_loss: 1.5669\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6164 - loss: 0.6810 - val_accuracy: 0.6533 - val_loss: 1.1119\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6594 - loss: 0.6898 - val_accuracy: 0.6533 - val_loss: 1.1882\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.6945 - loss: 0.7372 - val_accuracy: 0.6533 - val_loss: 1.2648\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.6714 - loss: 0.6757 - val_accuracy: 0.6400 - val_loss: 0.9986\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7326 - loss: 0.5396 - val_accuracy: 0.6533 - val_loss: 0.8565\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7163 - loss: 0.5630 - val_accuracy: 0.6533 - val_loss: 0.7667\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7366 - loss: 0.5817 - val_accuracy: 0.6533 - val_loss: 0.7494\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7219 - loss: 0.5349 - val_accuracy: 0.6400 - val_loss: 0.7060\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6820 - loss: 0.6380 - val_accuracy: 0.6533 - val_loss: 0.6700\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.7039 - loss: 0.5966 - val_accuracy: 0.6800 - val_loss: 0.6352\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7322 - loss: 0.5679 - val_accuracy: 0.6800 - val_loss: 0.6335\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7121 - loss: 0.5627 - val_accuracy: 0.6667 - val_loss: 0.6030\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7050 - loss: 0.5951 - val_accuracy: 0.6800 - val_loss: 0.6019\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.6522 - loss: 0.6209 - val_accuracy: 0.6667 - val_loss: 0.6170\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7302 - loss: 0.5473 - val_accuracy: 0.7200 - val_loss: 0.6255\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.6971 - loss: 0.5355 - val_accuracy: 0.7200 - val_loss: 0.6371\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7466 - loss: 0.5405 - val_accuracy: 0.6800 - val_loss: 0.6301\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7134 - loss: 0.5705 - val_accuracy: 0.6933 - val_loss: 0.6229\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7913 - loss: 0.4945 - val_accuracy: 0.6933 - val_loss: 0.6093\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7629 - loss: 0.5668 - val_accuracy: 0.7200 - val_loss: 0.6059\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7306 - loss: 0.5236 - val_accuracy: 0.7333 - val_loss: 0.6042\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7530 - loss: 0.5247 - val_accuracy: 0.7333 - val_loss: 0.6122\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7433 - loss: 0.5443 - val_accuracy: 0.7333 - val_loss: 0.6008\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7261 - loss: 0.5181 - val_accuracy: 0.7467 - val_loss: 0.6039\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7044 - loss: 0.5754 - val_accuracy: 0.7333 - val_loss: 0.6154\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.6675 - loss: 0.5491 - val_accuracy: 0.7600 - val_loss: 0.6065\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7639 - loss: 0.4796 - val_accuracy: 0.7467 - val_loss: 0.5945\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7330 - loss: 0.5123 - val_accuracy: 0.7733 - val_loss: 0.5908\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8274 - loss: 0.4179 - val_accuracy: 0.8133 - val_loss: 0.5822\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7642 - loss: 0.5349 - val_accuracy: 0.8000 - val_loss: 0.5913\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7314 - loss: 0.5429 - val_accuracy: 0.7867 - val_loss: 0.5893\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7152 - loss: 0.5404 - val_accuracy: 0.7867 - val_loss: 0.5814\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7440 - loss: 0.4852 - val_accuracy: 0.7867 - val_loss: 0.5533\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8049 - loss: 0.4633 - val_accuracy: 0.7600 - val_loss: 0.5452\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7264 - loss: 0.4997 - val_accuracy: 0.7333 - val_loss: 0.5497\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7924 - loss: 0.5306 - val_accuracy: 0.7333 - val_loss: 0.5564\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7841 - loss: 0.4788 - val_accuracy: 0.7600 - val_loss: 0.5513\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7609 - loss: 0.4937 - val_accuracy: 0.7600 - val_loss: 0.5377\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7383 - loss: 0.5338 - val_accuracy: 0.8000 - val_loss: 0.5342\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7442 - loss: 0.5072 - val_accuracy: 0.7867 - val_loss: 0.5491\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7638 - loss: 0.5007 - val_accuracy: 0.8000 - val_loss: 0.5786\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.6762 - loss: 0.5413 - val_accuracy: 0.7733 - val_loss: 0.5944\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7435 - loss: 0.5043 - val_accuracy: 0.7600 - val_loss: 0.6014\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8125 - loss: 0.4322 - val_accuracy: 0.7200 - val_loss: 0.6125\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7541 - loss: 0.4935 - val_accuracy: 0.7333 - val_loss: 0.5826\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7592 - loss: 0.4734 - val_accuracy: 0.7467 - val_loss: 0.5517\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7559 - loss: 0.4602 - val_accuracy: 0.7067 - val_loss: 0.5788\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.8068 - loss: 0.4572 - val_accuracy: 0.7067 - val_loss: 0.5733\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7223 - loss: 0.5138 - val_accuracy: 0.7333 - val_loss: 0.5526\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7593 - loss: 0.5015 - val_accuracy: 0.6400 - val_loss: 1.7683\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7480 - loss: 0.4788 - val_accuracy: 0.7067 - val_loss: 0.9115\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8163 - loss: 0.4353 - val_accuracy: 0.6800 - val_loss: 0.7852\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7801 - loss: 0.5188 - val_accuracy: 0.7200 - val_loss: 0.7681\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7627 - loss: 0.5036 - val_accuracy: 0.7200 - val_loss: 0.7459\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.8255 - loss: 0.4480 - val_accuracy: 0.7333 - val_loss: 0.7105\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8246 - loss: 0.4177 - val_accuracy: 0.6533 - val_loss: 0.7882\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7504 - loss: 0.4737 - val_accuracy: 0.6000 - val_loss: 0.7716\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7459 - loss: 0.4888 - val_accuracy: 0.5600 - val_loss: 0.7503\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.8126 - loss: 0.4488 - val_accuracy: 0.5600 - val_loss: 0.7068\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7945 - loss: 0.4626 - val_accuracy: 0.6267 - val_loss: 0.6728\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8136 - loss: 0.4364 - val_accuracy: 0.6533 - val_loss: 0.6420\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7857 - loss: 0.4613 - val_accuracy: 0.6667 - val_loss: 0.6064\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7811 - loss: 0.4875 - val_accuracy: 0.6667 - val_loss: 0.5914\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7133 - loss: 0.4653 - val_accuracy: 0.6933 - val_loss: 0.5871\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.7468 - loss: 0.5096 - val_accuracy: 0.5467 - val_loss: 0.7975\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8027 - loss: 0.4582 - val_accuracy: 0.5333 - val_loss: 0.8072\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7939 - loss: 0.4340 - val_accuracy: 0.4800 - val_loss: 0.7606\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7635 - loss: 0.4729 - val_accuracy: 0.5200 - val_loss: 0.7330\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.6880 - loss: 0.5585 - val_accuracy: 0.6400 - val_loss: 0.6389\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8205 - loss: 0.4199 - val_accuracy: 0.6933 - val_loss: 0.5897\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7118 - loss: 0.4503 - val_accuracy: 0.6667 - val_loss: 0.6030\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7521 - loss: 0.5125 - val_accuracy: 0.6667 - val_loss: 0.5989\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7192 - loss: 0.4811 - val_accuracy: 0.6533 - val_loss: 0.5538\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.8002 - loss: 0.4565 - val_accuracy: 0.7333 - val_loss: 0.5450\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7625 - loss: 0.4801 - val_accuracy: 0.7600 - val_loss: 0.5961\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.8181 - loss: 0.4660 - val_accuracy: 0.7200 - val_loss: 0.6052\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.8108 - loss: 0.4368 - val_accuracy: 0.7467 - val_loss: 0.6283\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7947 - loss: 0.4664 - val_accuracy: 0.7200 - val_loss: 0.6262\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.8037 - loss: 0.4354 - val_accuracy: 0.4133 - val_loss: 1.8550\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7398 - loss: 0.4978 - val_accuracy: 0.4800 - val_loss: 1.0472\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.7654 - loss: 0.4625 - val_accuracy: 0.5733 - val_loss: 0.7284\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.7633 - loss: 0.4731 - val_accuracy: 0.7200 - val_loss: 0.5955\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.7911 - loss: 0.4621 - val_accuracy: 0.7600 - val_loss: 0.5283\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7521 - loss: 0.4868 - val_accuracy: 0.7467 - val_loss: 0.5397\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.7623 - loss: 0.4927 - val_accuracy: 0.7600 - val_loss: 0.5590\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.7346 - loss: 0.4769 - val_accuracy: 0.7867 - val_loss: 0.5816\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8121 - loss: 0.4253 - val_accuracy: 0.7733 - val_loss: 0.5819\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.7994 - loss: 0.4247 - val_accuracy: 0.8133 - val_loss: 0.5631\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7847 - loss: 0.4368 - val_accuracy: 0.7733 - val_loss: 0.6186\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7634 - loss: 0.4271 - val_accuracy: 0.7733 - val_loss: 0.6227\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.8425 - loss: 0.3737 - val_accuracy: 0.7867 - val_loss: 0.6059\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7782 - loss: 0.4250 - val_accuracy: 0.7600 - val_loss: 0.5829\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.8052 - loss: 0.4256 - val_accuracy: 0.7600 - val_loss: 0.5997\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.7109 - loss: 0.5531 - val_accuracy: 0.7867 - val_loss: 0.6493\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7917 - loss: 0.4264 - val_accuracy: 0.7733 - val_loss: 0.6176\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.8565 - loss: 0.3795 - val_accuracy: 0.7600 - val_loss: 0.5895\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.7867 - loss: 0.4679 - val_accuracy: 0.7733 - val_loss: 0.5690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d95025a390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANN ALGORITHM \n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(224, 224, 3)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_set,\n",
    "          epochs=100,\n",
    "          validation_data=validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fad20b",
   "metadata": {},
   "source": [
    "## Test accuracy for ANN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d113cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 252 images belonging to 2 classes.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7369 - loss: 0.5545\n",
      "Test accuracy for ANN ALGORITHM : 0.7976190447807312\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\",\n",
    "    target_size=target_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy for ANN ALGORITHM :\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e5c8ab",
   "metadata": {},
   "source": [
    "### The classification_report provides the following metrics for each class:\n",
    "\n",
    "1. Precision: The proportion of correctly predicted positive instances (true positives) out of all instances predicted as positive (true positives + false positives).\n",
    "2. Recall: The proportion of correctly predicted positive instances (true positives) out of all actual positive instances (true positives + false negatives).\n",
    "3. F1-score: The harmonic mean of precision and recall, giving a balance between the two metrics. It is calculated as 2 * (precision * recall) / (precision + recall).\n",
    "4. Support: The number of actual occurrences of the class in the specified dataset.\n",
    "5. Accuracy: The proportion of correctly classified instances out of the total instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9592844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Report for ANN ALGORITHM \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.77      0.59      0.67        29\n",
      "         yes       0.77      0.89      0.83        46\n",
      "\n",
      "    accuracy                           0.77        75\n",
      "   macro avg       0.77      0.74      0.75        75\n",
      "weighted avg       0.77      0.77      0.77        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted labels for the validation set\n",
    "y_pred = model.predict(validation_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true labels for the validation set\n",
    "y_true = validation_set.classes\n",
    "\n",
    "# Compute the precision, recall, f1-score, and support\n",
    "target_names = ['no', 'yes']\n",
    "\n",
    "print(\"Report for ANN ALGORITHM \")\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216972a",
   "metadata": {},
   "source": [
    "# Tests each ANN model with new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8c80bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "The model predicts that the image shows yes tumor.\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(r\"Downloads\\yes2.jpeg\")\n",
    "\n",
    "# Preprocess the image\n",
    "\n",
    "img = cv2.resize(img, target_size)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "#Make the prediction\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Print the prediction\n",
    "if prediction[0][0] > 0.5:\n",
    "       print('The model predicts that the image shows no tumor.')\n",
    "else:\n",
    "       print('The model predicts that the image shows yes tumor.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "549bb01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "The model predicts that the image shows no tumor.\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(r\"Downloads\\no.jpg\")\n",
    "\n",
    "# Preprocess the image\n",
    "\n",
    "img = cv2.resize(img, target_size)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "#Make the prediction\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Print the prediction\n",
    "if prediction[0][0] > 0.5:\n",
    "       print('The model predicts that the image shows no tumor.')\n",
    "else:\n",
    "       print('The model predicts that the image shows yes tumor.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1bf7d",
   "metadata": {},
   "source": [
    "# CNN ALGORITHM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb90a822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed Bayomey\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5451 - loss: 1.8166 - val_accuracy: 0.6533 - val_loss: 0.5969\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6701 - loss: 0.5834 - val_accuracy: 0.7600 - val_loss: 0.5791\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7284 - loss: 0.5936 - val_accuracy: 0.7733 - val_loss: 0.5640\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7440 - loss: 0.5370 - val_accuracy: 0.7733 - val_loss: 0.5535\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 955ms/step - accuracy: 0.7591 - loss: 0.5551 - val_accuracy: 0.7733 - val_loss: 0.5408\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 954ms/step - accuracy: 0.7565 - loss: 0.5557 - val_accuracy: 0.7733 - val_loss: 0.5352\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 923ms/step - accuracy: 0.7870 - loss: 0.4739 - val_accuracy: 0.7467 - val_loss: 0.5466\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 968ms/step - accuracy: 0.7619 - loss: 0.5629 - val_accuracy: 0.7733 - val_loss: 0.5458\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 910ms/step - accuracy: 0.7826 - loss: 0.4821 - val_accuracy: 0.7867 - val_loss: 0.5339\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 936ms/step - accuracy: 0.7559 - loss: 0.4877 - val_accuracy: 0.7733 - val_loss: 0.5538\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 911ms/step - accuracy: 0.7168 - loss: 0.5935 - val_accuracy: 0.7600 - val_loss: 0.5641\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 918ms/step - accuracy: 0.6919 - loss: 0.5736 - val_accuracy: 0.7600 - val_loss: 0.5432\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 934ms/step - accuracy: 0.7439 - loss: 0.5487 - val_accuracy: 0.7733 - val_loss: 0.5180\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 909ms/step - accuracy: 0.7890 - loss: 0.5022 - val_accuracy: 0.7733 - val_loss: 0.5588\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 947ms/step - accuracy: 0.7131 - loss: 0.5231 - val_accuracy: 0.7600 - val_loss: 0.5370\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 993ms/step - accuracy: 0.7448 - loss: 0.5167 - val_accuracy: 0.7733 - val_loss: 0.5436\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 924ms/step - accuracy: 0.7708 - loss: 0.5632 - val_accuracy: 0.7600 - val_loss: 0.5336\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 988ms/step - accuracy: 0.7271 - loss: 0.5251 - val_accuracy: 0.7733 - val_loss: 0.5291\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 943ms/step - accuracy: 0.7669 - loss: 0.4872 - val_accuracy: 0.7867 - val_loss: 0.4839\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 931ms/step - accuracy: 0.7758 - loss: 0.4733 - val_accuracy: 0.8133 - val_loss: 0.4674\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 930ms/step - accuracy: 0.8226 - loss: 0.4296 - val_accuracy: 0.7733 - val_loss: 0.4582\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 960ms/step - accuracy: 0.7199 - loss: 0.5334 - val_accuracy: 0.7733 - val_loss: 0.5411\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7799 - loss: 0.5041 - val_accuracy: 0.7600 - val_loss: 0.5364\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 897ms/step - accuracy: 0.7212 - loss: 0.5003 - val_accuracy: 0.7867 - val_loss: 0.5671\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 913ms/step - accuracy: 0.6770 - loss: 0.6138 - val_accuracy: 0.8133 - val_loss: 0.5018\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 941ms/step - accuracy: 0.7836 - loss: 0.5049 - val_accuracy: 0.7867 - val_loss: 0.4821\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 935ms/step - accuracy: 0.7940 - loss: 0.5251 - val_accuracy: 0.7733 - val_loss: 0.4873\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 919ms/step - accuracy: 0.7889 - loss: 0.4205 - val_accuracy: 0.8000 - val_loss: 0.5081\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 911ms/step - accuracy: 0.8355 - loss: 0.4105 - val_accuracy: 0.7600 - val_loss: 0.5528\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 938ms/step - accuracy: 0.8057 - loss: 0.4433 - val_accuracy: 0.7467 - val_loss: 0.5738\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 904ms/step - accuracy: 0.7716 - loss: 0.5116 - val_accuracy: 0.7867 - val_loss: 0.4915\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 921ms/step - accuracy: 0.8384 - loss: 0.4548 - val_accuracy: 0.7600 - val_loss: 0.4967\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8399 - loss: 0.4494 - val_accuracy: 0.7600 - val_loss: 0.5325\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 952ms/step - accuracy: 0.8018 - loss: 0.4548 - val_accuracy: 0.7600 - val_loss: 0.5010\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 952ms/step - accuracy: 0.7930 - loss: 0.4437 - val_accuracy: 0.8000 - val_loss: 0.4647\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7858 - loss: 0.4739 - val_accuracy: 0.8000 - val_loss: 0.4355\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7801 - loss: 0.4733 - val_accuracy: 0.8667 - val_loss: 0.4362\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8835 - loss: 0.3279 - val_accuracy: 0.8800 - val_loss: 0.4480\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8466 - loss: 0.3889 - val_accuracy: 0.8400 - val_loss: 0.4514\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 936ms/step - accuracy: 0.8451 - loss: 0.4014 - val_accuracy: 0.8000 - val_loss: 0.5116\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 920ms/step - accuracy: 0.7528 - loss: 0.4710 - val_accuracy: 0.7733 - val_loss: 0.5179\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 971ms/step - accuracy: 0.8007 - loss: 0.4930 - val_accuracy: 0.7867 - val_loss: 0.5237\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 928ms/step - accuracy: 0.7639 - loss: 0.5136 - val_accuracy: 0.7467 - val_loss: 0.5174\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 907ms/step - accuracy: 0.8290 - loss: 0.3787 - val_accuracy: 0.7867 - val_loss: 0.5038\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 925ms/step - accuracy: 0.8326 - loss: 0.3899 - val_accuracy: 0.8000 - val_loss: 0.4520\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 927ms/step - accuracy: 0.8472 - loss: 0.4081 - val_accuracy: 0.7733 - val_loss: 0.4711\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 920ms/step - accuracy: 0.8337 - loss: 0.4095 - val_accuracy: 0.7333 - val_loss: 0.5204\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 923ms/step - accuracy: 0.8480 - loss: 0.3809 - val_accuracy: 0.7867 - val_loss: 0.4896\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 920ms/step - accuracy: 0.8706 - loss: 0.3219 - val_accuracy: 0.7600 - val_loss: 0.4892\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 919ms/step - accuracy: 0.8268 - loss: 0.4091 - val_accuracy: 0.7600 - val_loss: 0.5227\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 903ms/step - accuracy: 0.8249 - loss: 0.4497 - val_accuracy: 0.8000 - val_loss: 0.5212\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 968ms/step - accuracy: 0.8152 - loss: 0.4118 - val_accuracy: 0.8000 - val_loss: 0.4879\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 943ms/step - accuracy: 0.8479 - loss: 0.4058 - val_accuracy: 0.7867 - val_loss: 0.5543\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 992ms/step - accuracy: 0.8398 - loss: 0.3995 - val_accuracy: 0.7333 - val_loss: 0.5421\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 943ms/step - accuracy: 0.8464 - loss: 0.3975 - val_accuracy: 0.7867 - val_loss: 0.4896\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 949ms/step - accuracy: 0.8522 - loss: 0.4281 - val_accuracy: 0.8000 - val_loss: 0.4627\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 922ms/step - accuracy: 0.8045 - loss: 0.4163 - val_accuracy: 0.7733 - val_loss: 0.5061\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 920ms/step - accuracy: 0.8512 - loss: 0.3451 - val_accuracy: 0.8000 - val_loss: 0.5139\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 898ms/step - accuracy: 0.8227 - loss: 0.3559 - val_accuracy: 0.8000 - val_loss: 0.5157\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 985ms/step - accuracy: 0.8001 - loss: 0.3960 - val_accuracy: 0.8000 - val_loss: 0.5365\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 931ms/step - accuracy: 0.7736 - loss: 0.4489 - val_accuracy: 0.7733 - val_loss: 0.5373\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 978ms/step - accuracy: 0.8558 - loss: 0.3448 - val_accuracy: 0.7867 - val_loss: 0.5052\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 916ms/step - accuracy: 0.8220 - loss: 0.3623 - val_accuracy: 0.8133 - val_loss: 0.5230\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 909ms/step - accuracy: 0.8233 - loss: 0.4500 - val_accuracy: 0.8000 - val_loss: 0.5029\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 964ms/step - accuracy: 0.8454 - loss: 0.3681 - val_accuracy: 0.8267 - val_loss: 0.4555\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 926ms/step - accuracy: 0.8292 - loss: 0.3576 - val_accuracy: 0.8267 - val_loss: 0.4621\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 961ms/step - accuracy: 0.7979 - loss: 0.4601 - val_accuracy: 0.8133 - val_loss: 0.5320\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 924ms/step - accuracy: 0.8663 - loss: 0.3555 - val_accuracy: 0.8000 - val_loss: 0.5571\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 932ms/step - accuracy: 0.7939 - loss: 0.3785 - val_accuracy: 0.7733 - val_loss: 0.5416\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 946ms/step - accuracy: 0.7757 - loss: 0.3932 - val_accuracy: 0.8133 - val_loss: 0.5093\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9135 - loss: 0.2400 - val_accuracy: 0.7733 - val_loss: 0.6014\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 968ms/step - accuracy: 0.9048 - loss: 0.3401 - val_accuracy: 0.8000 - val_loss: 0.4961\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8787 - loss: 0.3192 - val_accuracy: 0.8267 - val_loss: 0.4813\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 927ms/step - accuracy: 0.8464 - loss: 0.3519 - val_accuracy: 0.8133 - val_loss: 0.5076\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 915ms/step - accuracy: 0.8545 - loss: 0.3187 - val_accuracy: 0.7333 - val_loss: 0.5668\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 971ms/step - accuracy: 0.8701 - loss: 0.3357 - val_accuracy: 0.7733 - val_loss: 0.5302\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 924ms/step - accuracy: 0.9014 - loss: 0.2656 - val_accuracy: 0.8133 - val_loss: 0.5866\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 912ms/step - accuracy: 0.8886 - loss: 0.4006 - val_accuracy: 0.8400 - val_loss: 0.5705\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 930ms/step - accuracy: 0.8761 - loss: 0.3211 - val_accuracy: 0.8133 - val_loss: 0.4835\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 927ms/step - accuracy: 0.8824 - loss: 0.2722 - val_accuracy: 0.8133 - val_loss: 0.4710\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 918ms/step - accuracy: 0.8668 - loss: 0.4041 - val_accuracy: 0.7600 - val_loss: 0.5290\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 904ms/step - accuracy: 0.8557 - loss: 0.3626 - val_accuracy: 0.8133 - val_loss: 0.5073\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 940ms/step - accuracy: 0.9051 - loss: 0.2793 - val_accuracy: 0.8133 - val_loss: 0.5420\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 916ms/step - accuracy: 0.8802 - loss: 0.2580 - val_accuracy: 0.8400 - val_loss: 0.5523\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 916ms/step - accuracy: 0.9107 - loss: 0.2716 - val_accuracy: 0.8000 - val_loss: 0.5458\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 934ms/step - accuracy: 0.8741 - loss: 0.2961 - val_accuracy: 0.8133 - val_loss: 0.5277\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 930ms/step - accuracy: 0.8920 - loss: 0.2896 - val_accuracy: 0.8533 - val_loss: 0.4991\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 963ms/step - accuracy: 0.8670 - loss: 0.3170 - val_accuracy: 0.8133 - val_loss: 0.5040\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 960ms/step - accuracy: 0.8935 - loss: 0.3135 - val_accuracy: 0.7867 - val_loss: 0.5233\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 998ms/step - accuracy: 0.8593 - loss: 0.2870 - val_accuracy: 0.7733 - val_loss: 0.5682\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 922ms/step - accuracy: 0.9044 - loss: 0.2866 - val_accuracy: 0.8133 - val_loss: 0.5876\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 917ms/step - accuracy: 0.8692 - loss: 0.2866 - val_accuracy: 0.8400 - val_loss: 0.4859\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 914ms/step - accuracy: 0.8004 - loss: 0.3618 - val_accuracy: 0.8667 - val_loss: 0.4828\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 899ms/step - accuracy: 0.8166 - loss: 0.3383 - val_accuracy: 0.8800 - val_loss: 0.4784\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 928ms/step - accuracy: 0.8557 - loss: 0.3922 - val_accuracy: 0.8267 - val_loss: 0.5548\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 910ms/step - accuracy: 0.9142 - loss: 0.2706 - val_accuracy: 0.8000 - val_loss: 0.5284\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 972ms/step - accuracy: 0.9437 - loss: 0.2216 - val_accuracy: 0.8267 - val_loss: 0.5574\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 914ms/step - accuracy: 0.9048 - loss: 0.2574 - val_accuracy: 0.8267 - val_loss: 0.6080\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 951ms/step - accuracy: 0.8787 - loss: 0.3121 - val_accuracy: 0.7600 - val_loss: 0.5511\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8543 - loss: 0.3008 - val_accuracy: 0.8000 - val_loss: 0.5367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d963130990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN ALGORITHM \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224,224, 3)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_set,\n",
    "          epochs=100,\n",
    "          validation_data=validation_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75401e52",
   "metadata": {},
   "source": [
    "## Test accuracy for CNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "324104ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 252 images belonging to 2 classes.\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.5625 - loss: 1.0706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed Bayomey\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.7959 - loss: 0.5062\n",
      "Test accuracy for CNN ALGORITHM : 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\",\n",
    "    target_size=target_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy for CNN ALGORITHM :\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd3425",
   "metadata": {},
   "source": [
    "### The classification_report provides the following metrics for each class:\n",
    "\n",
    "1. Precision: The proportion of correctly predicted positive instances (true positives) out of all instances predicted as positive (true positives + false positives).\n",
    "2. Recall: The proportion of correctly predicted positive instances (true positives) out of all actual positive instances (true positives + false negatives).\n",
    "3. F1-score: The harmonic mean of precision and recall, giving a balance between the two metrics. It is calculated as 2 * (precision * recall) / (precision + recall).\n",
    "4. Support: The number of actual occurrences of the class in the specified dataset.\n",
    "5. Accuracy: The proportion of correctly classified instances out of the total instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa704509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 163ms/stepWARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D966366840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step\n",
      "Report for CNN ALGORITHM \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.89      0.55      0.68        29\n",
      "         yes       0.77      0.96      0.85        46\n",
      "\n",
      "    accuracy                           0.80        75\n",
      "   macro avg       0.83      0.75      0.77        75\n",
      "weighted avg       0.82      0.80      0.79        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted labels for the validation set\n",
    "y_pred = model.predict(validation_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true labels for the validation set\n",
    "y_true = validation_set.classes\n",
    "\n",
    "# Compute the precision, recall, f1-score, and support\n",
    "target_names = ['no', 'yes']\n",
    "\n",
    "print(\"Report for CNN ALGORITHM \")\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703094ec",
   "metadata": {},
   "source": [
    "# Tests each CNN model with new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "036be973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D966366840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "The model predicts that the image shows yes tumor.\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(\"Downloads\\yes.jpeg\")\n",
    "\n",
    "# Preprocess the image\n",
    "img = cv2.resize(img, target_size)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "#Make the prediction\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Print the prediction\n",
    "if prediction[0][0] > 0.5:\n",
    "       print('The model predicts that the image shows no tumor.')\n",
    "else:\n",
    "       print('The model predicts that the image shows yes tumor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba84f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "The model predicts that the image shows yes tumor.\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(\"Downloads\\yes2.jpeg\")\n",
    "\n",
    "# Preprocess the image\n",
    "img = cv2.resize(img, target_size)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "#Make the prediction\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Print the prediction\n",
    "if prediction[0][0] > 0.5:\n",
    "       print('The model predicts that the image shows no tumor.')\n",
    "else:\n",
    "       print('The model predicts that the image shows yes tumor.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9025f3",
   "metadata": {},
   "source": [
    "# SVM ALGORITHM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "169c921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.5228 - loss: 0.9936 - val_accuracy: 0.5867 - val_loss: 0.9664\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5696 - loss: 0.9326 - val_accuracy: 0.6000 - val_loss: 0.9639\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.6136 - loss: 0.9069 - val_accuracy: 0.6667 - val_loss: 0.9179\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6784 - loss: 0.8531 - val_accuracy: 0.6133 - val_loss: 0.9463\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6499 - loss: 0.8863 - val_accuracy: 0.6533 - val_loss: 0.9428\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7161 - loss: 0.8333 - val_accuracy: 0.5600 - val_loss: 0.9398\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7247 - loss: 0.8593 - val_accuracy: 0.6533 - val_loss: 0.9400\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6702 - loss: 0.8570 - val_accuracy: 0.6400 - val_loss: 0.9613\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6670 - loss: 0.8661 - val_accuracy: 0.6667 - val_loss: 0.9264\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7560 - loss: 0.7928 - val_accuracy: 0.6267 - val_loss: 0.9472\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6771 - loss: 0.8395 - val_accuracy: 0.6800 - val_loss: 0.9174\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7632 - loss: 0.7849 - val_accuracy: 0.6667 - val_loss: 0.8940\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7248 - loss: 0.8086 - val_accuracy: 0.7067 - val_loss: 0.9004\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7247 - loss: 0.8172 - val_accuracy: 0.7067 - val_loss: 0.8683\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.6963 - loss: 0.8357 - val_accuracy: 0.7067 - val_loss: 0.8512\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7027 - loss: 0.8195 - val_accuracy: 0.7067 - val_loss: 0.8492\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6814 - loss: 0.8495 - val_accuracy: 0.6933 - val_loss: 0.8468\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6553 - loss: 0.8636 - val_accuracy: 0.7200 - val_loss: 0.8191\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.6949 - loss: 0.8391 - val_accuracy: 0.7067 - val_loss: 0.8252\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7624 - loss: 0.7826 - val_accuracy: 0.7467 - val_loss: 0.8107\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7733 - loss: 0.7898 - val_accuracy: 0.7467 - val_loss: 0.8023\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8089 - loss: 0.7678 - val_accuracy: 0.7600 - val_loss: 0.7964\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7586 - loss: 0.7869 - val_accuracy: 0.7333 - val_loss: 0.8120\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7802 - loss: 0.7680 - val_accuracy: 0.7200 - val_loss: 0.8157\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7154 - loss: 0.8256 - val_accuracy: 0.7333 - val_loss: 0.7987\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7355 - loss: 0.7971 - val_accuracy: 0.7467 - val_loss: 0.7809\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7792 - loss: 0.7634 - val_accuracy: 0.7867 - val_loss: 0.7805\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7653 - loss: 0.7614 - val_accuracy: 0.7867 - val_loss: 0.7679\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7177 - loss: 0.7967 - val_accuracy: 0.7467 - val_loss: 0.8264\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7914 - loss: 0.7573 - val_accuracy: 0.7467 - val_loss: 0.8190\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8113 - loss: 0.7508 - val_accuracy: 0.7600 - val_loss: 0.8059\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7951 - loss: 0.7550 - val_accuracy: 0.7067 - val_loss: 0.8339\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7352 - loss: 0.8097 - val_accuracy: 0.7467 - val_loss: 0.8112\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7122 - loss: 0.8034 - val_accuracy: 0.7867 - val_loss: 0.7946\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7329 - loss: 0.7856 - val_accuracy: 0.7867 - val_loss: 0.7927\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7234 - loss: 0.7922 - val_accuracy: 0.7733 - val_loss: 0.7803\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.6599 - loss: 0.8312 - val_accuracy: 0.7733 - val_loss: 0.7906\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7838 - loss: 0.7734 - val_accuracy: 0.7867 - val_loss: 0.7825\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7794 - loss: 0.7682 - val_accuracy: 0.7733 - val_loss: 0.8088\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7350 - loss: 0.7953 - val_accuracy: 0.6800 - val_loss: 0.8403\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7868 - loss: 0.7578 - val_accuracy: 0.7200 - val_loss: 0.8194\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7630 - loss: 0.7647 - val_accuracy: 0.7600 - val_loss: 0.7869\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7588 - loss: 0.7580 - val_accuracy: 0.6933 - val_loss: 0.8078\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8201 - loss: 0.7357 - val_accuracy: 0.7600 - val_loss: 0.7995\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7308 - loss: 0.7930 - val_accuracy: 0.7333 - val_loss: 0.8107\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.7793 - val_accuracy: 0.7600 - val_loss: 0.7891\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.7060 - loss: 0.7999 - val_accuracy: 0.7600 - val_loss: 0.7774\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7681 - loss: 0.7685 - val_accuracy: 0.7200 - val_loss: 0.7842\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7399 - loss: 0.8038 - val_accuracy: 0.7467 - val_loss: 0.7794\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8207 - loss: 0.7344 - val_accuracy: 0.7467 - val_loss: 0.7647\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8000 - loss: 0.7288 - val_accuracy: 0.7600 - val_loss: 0.7541\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7699 - loss: 0.7599 - val_accuracy: 0.7600 - val_loss: 0.7598\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7928 - loss: 0.7429 - val_accuracy: 0.6800 - val_loss: 0.8038\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7686 - loss: 0.7643 - val_accuracy: 0.7333 - val_loss: 0.7868\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7850 - loss: 0.7506 - val_accuracy: 0.7333 - val_loss: 0.7727\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7826 - loss: 0.7534 - val_accuracy: 0.7600 - val_loss: 0.7797\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7567 - loss: 0.7633 - val_accuracy: 0.7600 - val_loss: 0.7625\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7064 - loss: 0.8137 - val_accuracy: 0.7733 - val_loss: 0.7551\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7510 - loss: 0.7728 - val_accuracy: 0.7467 - val_loss: 0.7656\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7992 - loss: 0.7438 - val_accuracy: 0.7867 - val_loss: 0.7418\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7673 - loss: 0.7491 - val_accuracy: 0.7467 - val_loss: 0.7960\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7896 - loss: 0.7436 - val_accuracy: 0.7467 - val_loss: 0.7932\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7888 - loss: 0.7305 - val_accuracy: 0.6800 - val_loss: 0.8267\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8146 - loss: 0.7603 - val_accuracy: 0.7467 - val_loss: 0.7869\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7385 - loss: 0.7735 - val_accuracy: 0.7333 - val_loss: 0.7781\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7720 - loss: 0.7543 - val_accuracy: 0.7600 - val_loss: 0.7677\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7618 - loss: 0.7538 - val_accuracy: 0.7600 - val_loss: 0.7577\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7624 - loss: 0.7651 - val_accuracy: 0.7733 - val_loss: 0.7461\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7090 - loss: 0.7949 - val_accuracy: 0.7733 - val_loss: 0.7520\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7664 - loss: 0.7568 - val_accuracy: 0.7467 - val_loss: 0.7710\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8050 - loss: 0.7319 - val_accuracy: 0.7467 - val_loss: 0.7789\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8088 - loss: 0.7318 - val_accuracy: 0.7333 - val_loss: 0.7629\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7529 - loss: 0.7571 - val_accuracy: 0.7733 - val_loss: 0.7336\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7521 - loss: 0.7775 - val_accuracy: 0.8000 - val_loss: 0.7376\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7421 - loss: 0.7834 - val_accuracy: 0.7867 - val_loss: 0.7400\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8077 - loss: 0.7309 - val_accuracy: 0.7867 - val_loss: 0.7280\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7933 - loss: 0.7481 - val_accuracy: 0.7867 - val_loss: 0.7267\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7190 - loss: 0.7890 - val_accuracy: 0.7467 - val_loss: 0.7619\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8029 - loss: 0.7380 - val_accuracy: 0.7600 - val_loss: 0.7611\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6889 - loss: 0.8090 - val_accuracy: 0.7733 - val_loss: 0.7474\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8108 - loss: 0.7208 - val_accuracy: 0.7600 - val_loss: 0.7579\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7993 - loss: 0.7331 - val_accuracy: 0.7467 - val_loss: 0.7744\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7596 - loss: 0.7618 - val_accuracy: 0.6667 - val_loss: 0.8007\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7966 - loss: 0.7356 - val_accuracy: 0.7733 - val_loss: 0.7556\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.8247 - loss: 0.7044 - val_accuracy: 0.7067 - val_loss: 0.8300\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.7540 - loss: 0.7658 - val_accuracy: 0.7600 - val_loss: 0.7980\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8038 - loss: 0.7150 - val_accuracy: 0.7867 - val_loss: 0.7668\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7408 - loss: 0.7703 - val_accuracy: 0.7733 - val_loss: 0.7537\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7804 - loss: 0.7680 - val_accuracy: 0.7733 - val_loss: 0.7583\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7292 - loss: 0.7990 - val_accuracy: 0.7067 - val_loss: 0.8147\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7647 - loss: 0.7606 - val_accuracy: 0.7600 - val_loss: 0.7771\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8151 - loss: 0.7326 - val_accuracy: 0.7733 - val_loss: 0.7618\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7301 - loss: 0.7708 - val_accuracy: 0.7600 - val_loss: 0.7814\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.8032 - loss: 0.7274 - val_accuracy: 0.7733 - val_loss: 0.7808\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.8047 - loss: 0.7161 - val_accuracy: 0.7200 - val_loss: 0.8027\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7920 - loss: 0.7421 - val_accuracy: 0.7600 - val_loss: 0.7831\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7273 - loss: 0.7819 - val_accuracy: 0.7333 - val_loss: 0.7958\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7746 - loss: 0.7564 - val_accuracy: 0.7600 - val_loss: 0.7959\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7686 - loss: 0.7625 - val_accuracy: 0.7733 - val_loss: 0.7743\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7562 - loss: 0.7792 - val_accuracy: 0.7867 - val_loss: 0.7580\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(224, 224, 3)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model with a custom loss function for SVM\n",
    "model.compile(optimizer=SGD(), loss='hinge', metrics=['accuracy'])\n",
    "\n",
    "# Train the SVM model using fit_generator\n",
    "history = model.fit(training_set,\n",
    "          epochs=100,\n",
    "          validation_data=validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66471cec",
   "metadata": {},
   "source": [
    "# Test accuracy for SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c791e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 252 images belonging to 2 classes.\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6901 - loss: 0.8133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed Bayomey\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7409 - loss: 0.7745\n",
      "Test accuracy for SVM ALGORITHM : 0.8095238208770752\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r\"F:\\LEVEL 3 1\\Data Science Tools and Software\\brain mri\\brain_tumor_dataset\",\n",
    "    target_size=target_size,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy for SVM ALGORITHM :\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01031bf8",
   "metadata": {},
   "source": [
    "### The classification_report provides the following metrics for each class:\n",
    "\n",
    "1. Precision: The proportion of correctly predicted positive instances (true positives) out of all instances predicted as positive (true positives + false positives).\n",
    "2. Recall: The proportion of correctly predicted positive instances (true positives) out of all actual positive instances (true positives + false negatives).\n",
    "3. F1-score: The harmonic mean of precision and recall, giving a balance between the two metrics. It is calculated as 2 * (precision * recall) / (precision + recall).\n",
    "4. Support: The number of actual occurrences of the class in the specified dataset.\n",
    "5. Accuracy: The proportion of correctly classified instances out of the total instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e07a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Report for SVM ALGORITHM \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.76      0.66      0.70        29\n",
      "         yes       0.80      0.87      0.83        46\n",
      "\n",
      "    accuracy                           0.79        75\n",
      "   macro avg       0.78      0.76      0.77        75\n",
      "weighted avg       0.78      0.79      0.78        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted labels for the validation set\n",
    "y_pred = model.predict(validation_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get the true labels for the validation set\n",
    "y_true = validation_set.classes\n",
    "\n",
    "# Compute the precision, recall, f1-score, and support\n",
    "target_names = ['no', 'yes']\n",
    "\n",
    "print(\"Report for SVM ALGORITHM \")\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13472071",
   "metadata": {},
   "source": [
    "# Tests each SVM model with new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fe406e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "The model predicts that the image shows yes tumor.\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(r\"Downloads\\yes2.jpeg\")\n",
    "\n",
    "# Preprocess the image\n",
    "img = cv2.resize(img, target_size)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "#Make the prediction\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Print the prediction\n",
    "if prediction[0][0] > 0.5:\n",
    "       print('The model predicts that the image shows no tumor.')\n",
    "else:\n",
    "       print('The model predicts that the image shows yes tumor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19a07eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "The model predicts that the image shows yes tumor.\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(r\"Downloads\\yes.jpeg\")\n",
    "\n",
    "# Preprocess the image\n",
    "img = cv2.resize(img, target_size)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "#Make the prediction\n",
    "prediction = model.predict(img)\n",
    "\n",
    "# Print the prediction\n",
    "if prediction[0][0] > 0.5:\n",
    "       print('The model predicts that the image shows no tumor.')\n",
    "else:\n",
    "       print('The model predicts that the image shows yes tumor.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
